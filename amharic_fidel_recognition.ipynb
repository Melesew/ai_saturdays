{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = sorted(glob.glob('amharic_fidel_images/fidels/*/*.jpg'))\n",
    "test_files = sorted(glob.glob('amharic_fidel_images/fidel_test/*/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I :  (720, 438)\n",
      "k :  [225]\n",
      "(720, 446)\n",
      "J : (720, 446)\n"
     ]
    }
   ],
   "source": [
    "I = Image.open(train_files[0]).size\n",
    "print('I : ',I)\n",
    "j = []\n",
    "k = []\n",
    "for i in train_files:\n",
    "    #print(\"the size of \" , train_files.index(i), \"\\t\" , Image.open(i).size) \n",
    "    if(Image.open(i).size == I):\n",
    "        j.append(train_files.index(i))\n",
    "    else:\n",
    "        k.append(train_files.index(i))\n",
    "        \n",
    "\n",
    "# print(j)\n",
    "print('k : ', k)\n",
    "print(Image.open(train_files[225]).size)\n",
    "J = Image.open(train_files[225]).size\n",
    "print('J :', J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = []\n",
    "all_y = []\n",
    "\n",
    "for i in train_files:\n",
    "    if(i == train_files[225]):\n",
    "        all_x.append(np.array(Image.open(i).convert('L')).reshape(-1, 1)[:315360, :])\n",
    "    else:\n",
    "        all_x.append(np.array(Image.open(i).convert('L')).reshape(-1, 1))\n",
    "    all_y.append(i.split('/')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(all_x)\n",
    "\n",
    "y = np.array(all_y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 315360, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 315360)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.squeeze()\n",
    "X.shape # shape of X = (m,n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "00\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "01\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "02\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "03\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "04\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "05\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "06\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "07\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "08\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "09\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for i in y:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_to_b = []\n",
    "for i in y:\n",
    "    row = [0]*14\n",
    "    row[int(i[0])-1] = 1\n",
    "    y_to_b.append(row)\n",
    "y_to_b = np.array(y_to_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 14)\n",
      "(411, 315360)\n"
     ]
    }
   ],
   "source": [
    "print(y_to_b.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model():\n",
    "    def __init__(self, X, num_class): \n",
    "        self.weights = np.random.rand(X.shape[1], num_class) \n",
    "        #self.weights = np.zeros((X.shape[1], num_class)) \n",
    "        self.biases = np.zeros(shape = (1, num_class))\n",
    "        self.X = X\n",
    "        self.num_class = num_class\n",
    "         \n",
    "    def forward(self, X, w, b):\n",
    "        return np.matmul(X, w) + b\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        z -= np.max(z, axis = 1).reshape(-1, 1)\n",
    "        return np.exp(z) / np.array(np.sum(np.exp(z), axis = 1)).reshape(-1, 1)\n",
    "        \n",
    "    def cost(self, softmax, y):\n",
    "        #m = y.shape[0]\n",
    "        #cost = (- 1 / m) * np.sum(y * np.log(softmax) + (1 - y) * (np.log(1 - softmax)))  # compute cost\n",
    "        \n",
    "        #loss = (y * np.log(softmax)) + (1-y) * (np.log(1 - softmax))\n",
    "        loss = np.multiply(y, np.log(softmax)) + np.multiply(y, np.log(1 - softmax))\n",
    "        num_image = y.shape[0]\n",
    "        cost = - np.sum(loss) / num_image\n",
    "        cost = np.squeeze(cost)\n",
    "        return cost\n",
    "    \n",
    "    def gradient_cost(self, X, softmax, y):\n",
    "        loss = self.loss\n",
    "    #this loss1 is the cross entropy cost\n",
    "    \n",
    "    def cross_entropy_cost(self, softmax, y):\n",
    "        cost = -np.sum(np.multiply(y, np.log(softmax + 0.01)))\n",
    "        #cost = -np.sum(np.multiply(y, np.log(softmax[:, y])))\n",
    "        return cost\n",
    "    \n",
    "         \n",
    "    def backward(self, X, softmax, y):\n",
    "        m = X.shape[1]\n",
    "        dw = (1 / m) * np.dot(X.T, (softmax - y))\n",
    "        db = (1 / m) * np.sum(softmax - y)\n",
    "        return dw, db\n",
    "    \n",
    "    def update_parameters(self, dw, db, alpha, w_old, b_old):\n",
    "        w_new = w_old - alpha * dw\n",
    "        b_new = b_old - alpha * db \n",
    "        return w_new, b_new\n",
    "    \n",
    "    def update_parameters_2(self, X, cost, lr, w_old, b_old):\n",
    "        \n",
    "        w_new = w_old - np.dot(lr, np.multiply(X, cost))\n",
    "        b_new = b_old - np.dot(lr, np.sum(cost))\n",
    "        \n",
    "        return w_new, b_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 14\n",
    "model = model(X, num_class)\n",
    "w = model.weights\n",
    "b = model.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315360, 14)\n",
      "[[0.59438558 0.0761503  0.36539519 ... 0.14234341 0.37626372 0.0522706 ]\n",
      " [0.50397367 0.05721941 0.65289646 ... 0.55298317 0.88478932 0.73324626]\n",
      " [0.06385445 0.75558441 0.88001538 ... 0.36454949 0.14050563 0.84066262]\n",
      " ...\n",
      " [0.02513943 0.65839338 0.13813729 ... 0.2373734  0.78393018 0.23763207]\n",
      " [0.03345367 0.90525867 0.17498159 ... 0.57808999 0.5867684  0.3617925 ]\n",
      " [0.81957762 0.00952564 0.16355166 ... 0.24965257 0.11121821 0.0775684 ]]\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.forward(X, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the output array becomes (411, 14)\n",
      "\n",
      "The forward output of all the image\n",
      "\n",
      "[[389951.50477573 394807.43941101 393362.2249713  ... 390414.58909842\n",
      "  381969.73201849 391900.86681566]\n",
      " [415925.23812816 415300.58780628 411527.57418472 ... 408218.79611347\n",
      "  405915.16060016 406541.62237463]\n",
      " [430073.24905149 431690.58115578 431241.69380878 ... 436884.93008754\n",
      "  431699.87266732 424293.93098348]\n",
      " ...\n",
      " [570935.07041408 577974.78400585 580649.86810861 ... 562961.43455461\n",
      "  568121.45368691 567856.24999438]\n",
      " [605544.66815666 617549.15867877 606016.95425982 ... 604897.64972499\n",
      "  600829.68623392 611064.62834541]\n",
      " [570741.23375456 572383.76023949 573550.61883305 ... 580228.7949793\n",
      "  577347.43832165 580748.4872004 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the output array becomes\", a.shape)\n",
    "print(\"\\nThe forward output of all the image\\n\")\n",
    "print(a)\n",
    "#print(\"\\nThe forward output of the 20th image how much it is means the prediction through the 14 class\")\n",
    "#print(a[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Result\n",
    "\n",
    "The shape of the output array becomes (411, 14)\n",
    "\n",
    "The forward output of all the image\n",
    "\n",
    "The forward output of the 20th image how much it is means the prediction through the 14 class [474244.45342753 480183.38392286 471674.62918 478515.06985859 464605.62585467 477473.93646667 473011.59488537 478671.92048778 461979.22081921 470068.8819789 480149.49769161 469849.74504296 466378.11909758 472072.12665338]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the prediction of an array output becomes (411, 14)\n",
      "\n",
      " [[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 2.31951606e-295\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 1.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.99772676e-226\n",
      "  0.00000000e+000 1.00000000e+000]]\n",
      "\n",
      "checking the softmax by summing their values\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "softmax = model.softmax(a)\n",
    "print(\"The shape of the prediction of an array output becomes\", softmax.shape)\n",
    "print(\"\\n\", softmax)\n",
    "\n",
    "print(\"\\nchecking the softmax by summing their values\")\n",
    "print(np.sum(softmax[165]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss is nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "#loss = model.cross_entropy_cost(softmax, y_to_b)\n",
    "loss = model.cost(softmax, y_to_b)\n",
    "\n",
    "print(\"the loss is\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = model.cross_entropy_cost(softmax, y_to_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw, db = model.backward(X, softmax, y_to_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(315360, 14)\n"
     ]
    }
   ],
   "source": [
    "print(dw)\n",
    "print(dw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (315360,14) (411,315360) ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a141c9faef8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mu_w1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_b1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_parameters_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-5d3c17a13ae0>\u001b[0m in \u001b[0;36mupdate_parameters_2\u001b[0;34m(self, X, cost, lr, w_old, b_old)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_parameters_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mw_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_old\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mb_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_old\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (315360,14) (411,315360) "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "u_w1, u_b1 = model.update_parameters(dw, db, 0.01, w, b)\n",
    "w, b = model.update_parameters_2(X, cost, 0.01, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59438558 0.0761503  0.36539519 ... 0.14234341 0.37626372 0.0522706 ]\n",
      " [0.50397367 0.05721941 0.65289646 ... 0.55298317 0.88478932 0.73324626]\n",
      " [0.06385445 0.75558441 0.88001538 ... 0.36454949 0.14050563 0.84066262]\n",
      " ...\n",
      " [0.02513943 0.65839338 0.13813729 ... 0.2373734  0.78393018 0.23763207]\n",
      " [0.03345367 0.90525867 0.17498159 ... 0.57808999 0.5867684  0.3617925 ]\n",
      " [0.81957762 0.00952564 0.16355166 ... 0.24965257 0.11121821 0.0775684 ]]\n",
      "(315360, 14)\n"
     ]
    }
   ],
   "source": [
    "print(u_w1)\n",
    "print(u_w1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward2 = model.forward(X, u_w1, u_b1)\n",
    "\n",
    "softmax2 = model.softmax(forward2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2 = model.cross_entropy_cost(softmax2, y_to_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740.4259693849951\n"
     ]
    }
   ],
   "source": [
    "print(loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'model' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7d615fbb7422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'model' object is not callable"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "num_class = 14\n",
    "model = model(X, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.weights\n",
    "b = model.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Loss in Step  0  is \t nan\n",
      "The Loss in Step  1  is \t nan\n",
      "The Loss in Step  2  is \t nan\n",
      "The Loss in Step  3  is \t nan\n",
      "The Loss in Step  4  is \t nan\n",
      "The Loss in Step  5  is \t nan\n",
      "The Loss in Step  6  is \t nan\n",
      "The Loss in Step  7  is \t nan\n",
      "The Loss in Step  8  is \t nan\n",
      "The Loss in Step  9  is \t nan\n"
     ]
    }
   ],
   "source": [
    "#print(\"initial weight\\n\\t\", w)\n",
    "#print(\"\\ninitial bias\\n\\t\", b )\n",
    "for i in range(10):\n",
    "    #print(\"\\nweight \", i , \"\\n\\t\", w)\n",
    "    #print(\"\\nbias \", i, \"\\n\\t\", b )\n",
    "    forward = model.forward(X, w, b)\n",
    "    soft = model.softmax(forward)\n",
    "    #cost = model.cross_entropy_cost(soft, y_to_b)\n",
    "    cost = model.cost(soft, y_to_b)\n",
    "    print(\"The Loss in Step \", i , \" is \\t\", cost)\n",
    "    dw, db = model.backward(X, soft, y_to_b)\n",
    "    w, b = model.update_parameters(dw, db, 0.001, w, b)\n",
    "    #w, b = model.update_parameters_2(X, cost, 0.01, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = tf.placeholder(tf.float32, shape = (411, 720*438*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = tf.placeholder(tf.float32, shape=[411, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = tf.Variable(tf.zeros((720*438*1, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = tf.Variable(tf.zeros((1, 14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 315360)\n",
      "(411, 315360)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(XX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315360, 14)\n",
      "(1, 14)\n"
     ]
    }
   ],
   "source": [
    "print(ww.shape)\n",
    "\n",
    "print(bb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 14)\n"
     ]
    }
   ],
   "source": [
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = tf.matmul(XX, ww)\n",
    "logit = tf.add(mat, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(411), Dimension(14)])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(labels=yy, logits=logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1084.6531\n",
      "255267.05\n",
      "1000963.75\n",
      "3412283.8\n",
      "343078.34\n",
      "3390.4219\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(15):\n",
    "        losss,_ = sess.run([loss,train], feed_dict={XX:X, yy:y_to_b})\n",
    "        print(str(losss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_loss(logits, labels):\n",
    "    cross_entropy_per_number = tf.nn.softmax_cross_entropy_with_logits_v2(labels = labels, logits = logits)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy_per_number)\n",
    "    tf.add_to_collection(\"loss\", cross_entropy)\n",
    "    return cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-72-e37a5ce7cbd9>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-72-e37a5ce7cbd9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(tf_loss(logit,\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(tf_loss(logit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(logits, labels):\n",
    "    prediction = tf.argmax(logits, 2)\n",
    "    actual = tf.argmax(labels, 2)\n",
    "    equal = tf.equal(prediction, actual)\n",
    "    # equal = tf.reduce_all(equal, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(equal, tf.float32), name=\"accuracy\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loss, learning_rate=0.00001):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss)\n",
    "    print(train_op)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"GradientDescent_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent_1/update_Variable/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent_1/update_Variable_1/ApplyGradientDescent\"\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent_1' type=NoOp>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(tf_loss(logit, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
